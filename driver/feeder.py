#!/usr/bin/env python3
#
# @Author: Josh Erb <josh.erb>
# @Date:   27-Feb-2017 10:02
# @Email:  josh.erb@excella.com
# @Last modified by:   josh.erb
# @Last modified time: 27-Feb-2017 10:02

"""
This script defines a feed class which will standardize the pulling and formatting
of multiple news publications' RSS feeds.

This object is referenced by the script named 'eater.py', which contains functions
that take the object as it's primary argument and serves as the primary driver for the
data ingestion of the project.
"""

#######################################
#   IMPORTS
#######################################
import requests
import pandas as pd
from datetime import datetime
from bs4 import BeautifulSoup

#######################################
#   CLASSES
#######################################

class ArticleFeed:
    """
    Stores RSS feed article data.

    Includes get() and dump() functions which, when used in tandem, will
    request RSS feed data, format, and save the data.
    """

    # All pulls must record whence and when each feed was read
    def __init__(self, feed, time=datetime.utcnow()):
        self.publication = feed
        self.observed_ts = time  # technically, the time this object was initialized

    def get(self, url):
        """
        A function to call the RSS url and collect titles, descriptions, and
        publication dates.

        Will append these to the object itself so that they can be used to
        dump the data to a csv (ultimately to be inserted into e
        a postgreSQL database)
        """
        # get data using requests module and BeautifulSoup
        feed = requests.get(url)
        feed_soup = BeautifulSoup(feed.content, 'html.parser')

        # make sure we've grabbed an actual RSS feed
        assert feed_soup.title != None, 'Legitimate feed not captured in response for {}.'.format(url)

        # put all article objects into a list
        feed_content = feed_soup.channel.find_all('item')

        # grab titles, descriptions, and pubdates and associate them with the object
        self.article_titles = [x.title.string for x in feed_content]
        self.descriptions = [x.description.string for x in feed_content]
        self.pubdates = [x.pubdate.string for x in feed_content]

        # need to ensure that length is the same for data frame columns that
        # are constant for each pull
        _stamps = (str(self.observed_ts) + '    ') * len(self.article_titles)
        _stamps = _stamps.split('    ')
        _stamps.pop()

        _pub = (self.publication + '    ') * len(self.article_titles)
        _pub = _pub.split('    ')
        _pub.pop()

        # turn all of the attributes into a dataframe
        relatable = pd.DataFrame({
            'observed_ts': _stamps,
            'publication': _pub,
            'title': self.article_titles,
            'description': self.descriptions,
            'pubdate': self.pubdates})

        # associate data with objects
        self.data = relatable

        return

    def dump(self, path):
        """
        Take a dataframe that was generated by the .get() function and save it
        to the specified path.
        """
        try:
            with open(path, 'a') as f:
                self.data.to_csv(f, header=False, index=False)

        except NameError:
            print('There is no data associated with this feed object.')

        return
